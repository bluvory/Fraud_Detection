{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Analysis\n",
    "- outlier: 나머지 데이터와 수치적으로 멀리 떨어져 있는 관측치거나 간단히 말해서 범위를 벗어나는 값\n",
    "\n",
    "## CAUSE FOR OUTLIERS \n",
    "- Data Entry Errors: 데이터 수집, 기록 또는 입력 중에 발생한 오류와 같은 entry 오류로 인한 데이터 이상값\n",
    "- Measurement Error: measurement instrument(계측기)의 결함\n",
    "- Natural Outlier: outlier가 오차로 인해 인공적이지 않을 때 발생, 대부분의 실제 데이터가 이 범주에 속함\n",
    "\n",
    "## OUTLIER DETECTION \n",
    "- outlier의 두가지 유형: Univariate / Multivariate\n",
    "- Unvariate: 단일 변수의 분포를 찾아볼 때 사용\n",
    "- Multivariate: n차원 공간의 outlier\n",
    "\n",
    "## DIFFERENT OUTLIER DETECTION TECHNIQUE. \n",
    "1. Hypothesis Testing\n",
    "2. Z-score method\n",
    "3. Robust Z-score\n",
    "4. I.Q.R method\n",
    "5. Winsorization method(Percentile Capping)\n",
    "6. DBSCAN Clustering\n",
    "7. Isolation Forest\n",
    "8. Visualizing the data\n",
    "   \n",
    " \n",
    "## 1. Hypothesis testing (Grubbs test)\n",
    "$$\n",
    "\\begin{array}{l}{\\text { Grubbs' test is defined for the hypothesis: }} \\\\ {\\begin{array}{ll}{\\text { Ho: }}  {\\text { There are no outliers in the data set }} \\\\ {\\mathrm{H}_{\\mathrm{1}} :}  {\\text { There is exactly one outlier in the data set }}\\end{array}}\\end{array}\n",
    "$$\n",
    "$$\n",
    "\\begin{array}{l}{\\text {The Grubbs' test statistic is defined as: }} \\\\ {\\qquad G_{calculated}=\\frac{\\max \\left|X_{i}-\\overline{X}\\right|}{SD}} \\\\ {\\text { with } \\overline{X} \\text { and } SD \\text { denoting the sample mean and standard deviation, respectively. }} \\end{array}\n",
    "$$\n",
    "$$\n",
    "G_{critical}=\\frac{(N-1)}{\\sqrt{N}} \\sqrt{\\frac{\\left(t_{\\alpha /(2 N), N-2}\\right)^{2}}{N-2+\\left(t_{\\alpha /(2 N), N-2}\\right)^{2}}}\n",
    "$$\n",
    "\n",
    "\\begin{array}{l}{\\text { If the calculated value is greater than critical, you can reject the null hypothesis and conclude that one of the values is an outlier }}\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:39.890199Z",
     "iopub.status.busy": "2021-03-14T09:56:39.889469Z",
     "iopub.status.idle": "2021-03-14T09:56:40.381606Z",
     "shell.execute_reply": "2021-03-14T09:56:40.380984Z"
    },
    "papermill": {
     "duration": 0.5221,
     "end_time": "2021-03-14T09:56:40.381759",
     "exception": false,
     "start_time": "2021-03-14T09:56:39.859659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grubbs Calculated Value: 1.4274928542926593\n",
      "Grubbs Critical Value: 1.887145117792422\n",
      "From grubbs_test we observe that calculated value is lesser than critical value, Accept null hypothesis and conclude that there is no outliers\n",
      "\n",
      "Grubbs Calculated Value: 2.2765147221587774\n",
      "Grubbs Critical Value: 2.019968507680656\n",
      "From grubbs_test we observe that calculated value is greater than critical value, Reject null hypothesis and conclude that there is an outliers\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "x = np.array([12,13,14,19,21,23])\n",
    "y = np.array([12,13,14,19,21,23,45])\n",
    "def grubbs_test(x):\n",
    "    n = len(x)\n",
    "    mean_x = np.mean(x)\n",
    "    sd_x = np.std(x)\n",
    "    numerator = max(abs(x-mean_x))\n",
    "    g_calculated = numerator/sd_x\n",
    "    print(\"Grubbs Calculated Value:\",g_calculated)\n",
    "    t_value = stats.t.ppf(1 - 0.05 / (2 * n), n - 2)\n",
    "    g_critical = ((n - 1) * np.sqrt(np.square(t_value))) / (np.sqrt(n) * np.sqrt(n - 2 + np.square(t_value)))\n",
    "    print(\"Grubbs Critical Value:\",g_critical)\n",
    "    if g_critical > g_calculated:\n",
    "        print(\"From grubbs_test we observe that calculated value is lesser than critical value, Accept null hypothesis and conclude that there is no outliers\\n\")\n",
    "    else:\n",
    "        print(\"From grubbs_test we observe that calculated value is greater than critical value, Reject null hypothesis and conclude that there is an outliers\\n\")\n",
    "grubbs_test(x)\n",
    "grubbs_test(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018251,
     "end_time": "2021-03-14T09:56:40.420162",
     "exception": false,
     "start_time": "2021-03-14T09:56:40.401911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div align='left'><font size=\"4\" color=\"#000000\"><h1 style=\"text-transform: uppercase\"><strong>2. Z-score method</strong> </font></div>\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\"> Using Z score method,we can find out how many standard deviations value away from the mean. </font></div> \n",
    "<img style=\"float: center;\"  src=\"https://i.pinimg.com/originals/cd/14/73/cd1473c4c82980c6596ea9f535a7f41c.jpg\" width=\"350px\">\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\">  Figure in the left shows area under normal curve and how much area that standard deviation covers. </font></div> \n",
    "<div align='left'><font size=\"3\" color=\"#000000\"> * 68% of the data points lie between + or - 1 standard deviation.</font></div>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\"> * 95% of the data points lie between + or - 2 standard deviation</font></div>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\"> * 99.7% of the data points lie between + or - 3 standard deviation</font></div>\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\"> Z-score formula</font></div>\n",
    "\n",
    "\\begin{array}{l} {Z score=\\frac{ X - Mean}{Standard Deviation}}  \\end{array}\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\"> If the z score of a data point is more than 3 (because it cover 99.7% of area), it indicates that the data value is quite different from the other values. It is taken as outliers.</font></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Z-score method\n",
    "- z-score를 사용하면 평균에서 몇 개의 표준 편차를 얻을 수 있는지 알 수 있음\n",
    "\n",
    "\\begin{array}{l} {Z score=\\frac{ X - Mean}{Standard Deviation}}  \\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:40.468937Z",
     "iopub.status.busy": "2021-03-14T09:56:40.468203Z",
     "iopub.status.idle": "2021-03-14T09:56:40.526804Z",
     "shell.execute_reply": "2021-03-14T09:56:40.525908Z"
    },
    "papermill": {
     "duration": 0.088254,
     "end_time": "2021-03-14T09:56:40.526979",
     "exception": false,
     "start_time": "2021-03-14T09:56:40.438725",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 개수: 4076\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../creditcard.csv')\n",
    "out = []\n",
    "\n",
    "def Zscore_outlier(df):\n",
    "    m = np.mean(df)\n",
    "    sd = np.std(df)\n",
    "    for i in df: \n",
    "        z = (i-m)/sd\n",
    "        if np.abs(z) > 3: \n",
    "            out.append(i)\n",
    "    return out\n",
    "\n",
    "print('Outlier 개수:', len(Zscore_outlier(data['Amount'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Robust z-score\n",
    "- median absolute deviation method\n",
    "- 파라미터가 일부 변경되는 Z-score method와 비슷함\n",
    "- 평균 및 표준 편차는 outlier의 영향을 많이 받으므로 이 모수를 변경해서 중위수 및 중위수에서 절대 편차를 사용\n",
    "\n",
    "\\begin{array}{l} {R.Z.score=\\frac{0.6745*( X_{i} - Median)}{MAD}}  \\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:40.615001Z",
     "iopub.status.busy": "2021-03-14T09:56:40.614292Z",
     "iopub.status.idle": "2021-03-14T09:56:40.734856Z",
     "shell.execute_reply": "2021-03-14T09:56:40.734263Z"
    },
    "papermill": {
     "duration": 0.150426,
     "end_time": "2021-03-14T09:56:40.735005",
     "exception": false,
     "start_time": "2021-03-14T09:56:40.584579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 개수: 52062\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "data = pd.read_csv('../creditcard.csv')\n",
    "out = []\n",
    "\n",
    "def ZRscore_outlier(df):\n",
    "    med = np.median(df)\n",
    "    ma = stats.median_abs_deviation(df)\n",
    "    \n",
    "    for i in df: \n",
    "        z = (0.6745*(i-med))/ (np.median(ma))\n",
    "        if np.abs(z) > 3: \n",
    "            out.append(i)\n",
    "    return out\n",
    "    \n",
    "print('Outlier 개수:', len(ZRscore_outlier(data['Amount'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. IQR method\n",
    "<img style=\"float: center;\"  src=\" https://miro.medium.com/max/18000/1*2c21SkzJMf3frPXPAR_gZA.png\" width=\"400px\">\n",
    "\n",
    "- (–1.5×IQR) ~ (+1.5×IQR) 범위 벗어나는 모든 값을 outlier로 처리\n",
    "- Q1 = 제1 사분위수 = data의 25%\n",
    "- Q2 = 제2 사분위수 = data의 50% = median\n",
    "- Q3 = 제3 사분위수 = data의 75%\n",
    "- (Q1–1.5*IQR): dataset에서 가장 작은 값, (Q3+1.5*IQR): dataset에서 가장 큰 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:40.822541Z",
     "iopub.status.busy": "2021-03-14T09:56:40.821827Z",
     "iopub.status.idle": "2021-03-14T09:56:40.865166Z",
     "shell.execute_reply": "2021-03-14T09:56:40.864336Z"
    },
    "papermill": {
     "duration": 0.072063,
     "end_time": "2021-03-14T09:56:40.865354",
     "exception": false,
     "start_time": "2021-03-14T09:56:40.793291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 개수: 31904\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../creditcard.csv')\n",
    "out = []\n",
    "\n",
    "def iqr_outliers(df):\n",
    "    \n",
    "    q1 = df.quantile(0.25)\n",
    "    q3 = df.quantile(0.75)\n",
    "    \n",
    "    iqr = q3-q1\n",
    "    \n",
    "    Lower_tail = q1 - 1.5 * iqr\n",
    "    Upper_tail = q3 + 1.5 * iqr\n",
    "    \n",
    "    for i in df:\n",
    "        if i > Upper_tail or i < Lower_tail:\n",
    "            out.append(i)\n",
    "    return out\n",
    "\n",
    "print('Outlier 개수:', len(iqr_outliers(data['Amount'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Winsorization method (percentile capping)\n",
    "- IQR method와 비슷함\n",
    "- (data의 1%) ~ (data의 99%) 범위 벗어나는 모든 값을 outlier로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:40.958788Z",
     "iopub.status.busy": "2021-03-14T09:56:40.958027Z",
     "iopub.status.idle": "2021-03-14T09:56:40.974321Z",
     "shell.execute_reply": "2021-03-14T09:56:40.973677Z"
    },
    "papermill": {
     "duration": 0.04747,
     "end_time": "2021-03-14T09:56:40.974468",
     "exception": false,
     "start_time": "2021-03-14T09:56:40.926998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier 개수: 5618\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('../creditcard.csv')\n",
    "out = []\n",
    "\n",
    "def Winsorization_outliers(df):\n",
    "    q1 = np.percentile(df , 1)\n",
    "    q3 = np.percentile(df , 99)\n",
    "    for i in df:\n",
    "        if i > q3 or i < q1:\n",
    "            out.append(i)\n",
    "    return out\n",
    "\n",
    "print('Outlier 개수:', len(Winsorization_outliers(data['Amount'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DBSCAN\n",
    "<img style=\"float: center;\"  src=\"https://qphs.fs.quoracdn.net/main-qimg-384458d7ab61f88e443b5e99bcd06622\" width=\"400px\">\n",
    "\n",
    "- DBSCAN은 데이터 세트를 고밀도 영역의 하위 그룹으로 나누고 고밀도 영역 클러스터를 이상값으로 식별하는 밀도 기반 클러스터링 알고리즘\n",
    "- 여기서 군집 -1은 군집에 특이치가 포함되어 있고 나머지 군집에는 특이치가 없음을 나타냅니다 (kmeans clustering과 유사)\n",
    "- 다변량 이상값 감지에 대한 최상의 결과를 제공\n",
    "- DBSCAN에는 두 가지 매개 변수가 필요\n",
    "1. epsilon: 근처 이웃을 검색할 반경을 정의하는 거리 매개 변수.\n",
    "2. 클러스터를 구성하는 데 필요한 최소 포인트 양\n",
    "\n",
    "**엡실론 및 minPts를 사용하여 각 데이터 지점을 다음과 같이 분류**\n",
    "- Core point: 반경 내에 최소 개수의 다른 포인트(minPts)가 있는 포인트.\n",
    "- border point: 점은 코어 점의 반경 내에 있지만 자체 반경 내에 다른 최소 포인트 수(minPts)보다 작습니다.\n",
    "- noise point: 핵심 포인트 또는 경계 포인트가 아닌 포인트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:41.065168Z",
     "iopub.status.busy": "2021-03-14T09:56:41.064441Z",
     "iopub.status.idle": "2021-03-14T09:56:41.702623Z",
     "shell.execute_reply": "2021-03-14T09:56:41.702071Z"
    },
    "papermill": {
     "duration": 0.667126,
     "end_time": "2021-03-14T09:56:41.702748",
     "exception": false,
     "start_time": "2021-03-14T09:56:41.035622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "data = pd.read_csv('../creditcard.csv')\n",
    "\n",
    "def DB_outliers(df):\n",
    "    outlier_detection = DBSCAN(eps = 2, metric='euclidean', min_samples = 5)\n",
    "    clusters = outlier_detection.fit_predict(df.values.reshape(-1,1))\n",
    "    data = pd.DataFrame()\n",
    "    data['cluster'] = clusters\n",
    "    return data['cluster'].value_counts().sort_values(ascending=False)\n",
    "    \n",
    "DB_outliers(data['Amount']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Isolation forest\n",
    "<img style=\"float: center;\"  src=\"https://miro.medium.com/max/875/0*0GuMixLdSZo3V3Nh.\" width=\"450px\">\n",
    "\n",
    "- random forest와 유사\n",
    "1. 데이터 점을 outlier와 not oulier로 분류하고 매우 높은 차원 데이터에서 잘 작동\n",
    "2. 의사결정 트리를 기반으로 작동하며 이상값을 격리(isolate)\n",
    "3. 결과가 -1이면 이 특정 데이터 점이 특이치임을 의미합니다. 결과가 1이면 데이터 점이 특이치가 아님을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:41.795442Z",
     "iopub.status.busy": "2021-03-14T09:56:41.794624Z",
     "iopub.status.idle": "2021-03-14T09:56:42.147168Z",
     "shell.execute_reply": "2021-03-14T09:56:42.147934Z"
    },
    "papermill": {
     "duration": 0.383354,
     "end_time": "2021-03-14T09:56:42.148162",
     "exception": false,
     "start_time": "2021-03-14T09:56:41.764808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('../creditcard.csv')\n",
    "\n",
    "train['Fare'].fillna(train[train.Pclass==3]['Fare'].median(),inplace=True)\n",
    "def Iso_outliers(df):\n",
    "    iso = IsolationForest( behaviour = 'new', random_state = 1, contamination= 'auto')\n",
    "    preds = iso.fit_predict(df.values.reshape(-1,1))\n",
    "    data = pd.DataFrame()\n",
    "    data['cluster'] = preds\n",
    "    print(data['cluster'].value_counts().sort_values(ascending=False))\n",
    "Iso_outliers(train['Fare']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizing the data\n",
    "- 데이터 시각화는 데이터 정리, 탐색, 이상치 탐지, 클러시터 식별에 유용\n",
    "1. Box and whisker plot (box plot)\n",
    "2. Scatter plot.\n",
    "3. Histogram.\n",
    "4. Distribution Plot.\n",
    "5. QQ plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:42.249119Z",
     "iopub.status.busy": "2021-03-14T09:56:42.243828Z",
     "iopub.status.idle": "2021-03-14T09:56:43.401490Z",
     "shell.execute_reply": "2021-03-14T09:56:43.401990Z"
    },
    "papermill": {
     "duration": 1.189154,
     "end_time": "2021-03-14T09:56:43.402166",
     "exception": false,
     "start_time": "2021-03-14T09:56:42.213012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "\n",
    "data = pd.read_csv('../creditcard.csv')\n",
    "\n",
    "def Box_plots(df):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(\"Box Plot\")\n",
    "    sns.boxplot(df)\n",
    "    plt.show()\n",
    "\n",
    "def hist_plots(df):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(df)\n",
    "    plt.title(\"Histogram Plot\")\n",
    "    plt.show()\n",
    "\n",
    "def scatter_plots(df1,df2):\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "    ax.scatter(df1,df2)\n",
    "    ax.set_xlabel('Age')\n",
    "    ax.set_ylabel('Fare')\n",
    "    plt.title(\"Scatter Plot\")\n",
    "    plt.show()\n",
    "\n",
    "def dist_plots(df):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.distplot(df)\n",
    "    plt.title(\"Distribution plot\")\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "def qq_plots(df):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    qqplot(df,line='s')\n",
    "    plt.title(\"Normal QQPlot\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "Box_plots(data['Amount'])\n",
    "hist_plots(data['Amount'])\n",
    "scatter_plots(data['Amount'],data['Time'])\n",
    "dist_plots(data['Amount'])\n",
    "qq_plots(data['Amount'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025923,
     "end_time": "2021-03-14T09:56:43.454918",
     "exception": false,
     "start_time": "2021-03-14T09:56:43.428995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div align='left'><font size=\"4\" color=\"#000000\"><h1 style=\"text-transform: uppercase\"><strong>What Next??</strong> </font></div>\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\">After detecting the outlier we should remove\\treat the outlier because <strong>it is a silent killer!!</strong> yes. </font></div> \n",
    "<hr>      \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* Outliers badly affect mean and standard deviation of the dataset. These may statistically give erroneous results.</font></div>     \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* It increases the error variance and reduces the power of statistical tests.</font></div>     \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* If the outliers are non-randomly distributed, they can decrease normality.</font></div> \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* Most machine learning algorithms do not work well in the presence of outlier. So it is desirable to detect and remove outliers.</font></div>     \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* They can also impact the basic assumption of Regression, ANOVA and other statistical model assumptions.</font></div> \n",
    "<hr>  \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">With all these reasons we must be careful about outlier and treat them before build a statistical/machine learning model. There are some techniques used to deal with outliers.</font></div> \n",
    "<hr>  \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">1. Deleting observations.</font></div>     \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">2. Transforming values.</font></div> \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">3. Imputation.</font></div>  \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">4. Separately treating</font></div> \n",
    "<hr>\n",
    "<div align='left'><font size=\"4\" color=\"#000000\"><h1 style=\"text-transform: uppercase\"><strong>Deleting observations:</strong> </font></div> \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">We delete outlier values if it is due to data entry error, data processing error or outlier observations are very small in numbers. We can also use trimming at both ends to remove outliers. But deleting the observation is not a good idea when we have small dataset.</font></div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 특이치는 데이터 세트의 평균 및 표준 편차에 좋지 않습니다. 이는 통계적으로 잘못된 결과를 제공할 수 있다.\n",
    "* 오차분산을 증가시키고 통계적 검정의 검정력을 감소시킨다.\n",
    "* 특이치가 랜덤하지 않게 분포되어 있으면 정규성이 저하될 수 있습니다.\n",
    "* 대부분의 기계 학습 알고리즘은 특이치가 있는 곳에서는 제대로 작동하지 않습니다. 따라서 특이치를 감지하고 제거하는 것이 바람직하다.\n",
    "* 회귀 분석, 분산 분석 및 기타 통계 모형 가정의 기본 가정에도 영향을 줄 수 있습니다.\n",
    "이러한 모든 이유로 우리는 통계/기계 학습 모델을 구축하기 전에 특이치를 주의하고 특이치를 처리해야 합니다. 이상값을 처리하는 데 사용되는 몇 가지 기술들이 있다.\n",
    "1. Deleting observations\n",
    "2. Transforming values\n",
    "3. Imputation\n",
    "4. Separately treating\n",
    "\n",
    "\n",
    "### 9-1 Deleting observations\n",
    "데이터 입력 오류, 데이터 처리 오류 또는 특이치 관측치의 수가 매우 적기 때문에 특이치 값을 삭제합니다. 이상값을 제거하기 위해 양쪽 끝을 다듬을 수도 있습니다. 그러나 작은 데이터 집합이 있는 경우 관찰 내용을 삭제하는 것은 좋지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:43.524013Z",
     "iopub.status.busy": "2021-03-14T09:56:43.523363Z",
     "iopub.status.idle": "2021-03-14T09:56:43.759698Z",
     "shell.execute_reply": "2021-03-14T09:56:43.760319Z"
    },
    "papermill": {
     "duration": 0.279389,
     "end_time": "2021-03-14T09:56:43.760487",
     "exception": false,
     "start_time": "2021-03-14T09:56:43.481098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "train = pd.read_csv('../input/cost-of-living/cost-of-living-2018.csv')\n",
    "sns.boxplot(train['Cost of Living Index'])\n",
    "plt.title(\"Box Plot before outlier removing\")\n",
    "plt.show()\n",
    "\n",
    "def drop_outliers(df, field_name):\n",
    "    iqr = 1.5 * (np.percentile(df[field_name], 75) - np.percentile(df[field_name], 25))\n",
    "    df.drop(df[df[field_name] > (iqr + np.percentile(df[field_name], 75))].index, inplace=True)\n",
    "    df.drop(df[df[field_name] < (np.percentile(df[field_name], 25) - iqr)].index, inplace=True)\n",
    "    \n",
    "drop_outliers(train, 'Cost of Living Index')\n",
    "sns.boxplot(train['Cost of Living Index'])\n",
    "plt.title(\"Box Plot after outlier removing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.026735,
     "end_time": "2021-03-14T09:56:43.815573",
     "exception": false,
     "start_time": "2021-03-14T09:56:43.788838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div align='left'><font size=\"4\" color=\"#000000\"><h1 style=\"text-transform: uppercase\"><strong>Transforming values:</strong> </font></div>\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\">Transforming variables can also eliminate outliers. These transformed values reduces the variation caused by extreme values.</font></div> \n",
    "<hr>   \n",
    " \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">1. Scalling</font></div>     \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">2. Log transformation</font></div> \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">3. Cube Root Normalization</font></div>  \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">4. Box-Cox transformation</font></div> \n",
    "<hr>\n",
    "    \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* These techniques convert values in the dataset to smaller values.</font></div>     \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* If the data has to many extreme values or skewed, this method helps to make your data normal.</font></div>     \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* But These technique not always give you the best results. </font></div> \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* There is no lose of data from these methods.</font></div>     \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">* In all these method boxcox transformation gives the best result.</font></div> \n",
    "<hr>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:43.881494Z",
     "iopub.status.busy": "2021-03-14T09:56:43.880499Z",
     "iopub.status.idle": "2021-03-14T09:56:44.226258Z",
     "shell.execute_reply": "2021-03-14T09:56:44.225687Z"
    },
    "papermill": {
     "duration": 0.382905,
     "end_time": "2021-03-14T09:56:44.226380",
     "exception": false,
     "start_time": "2021-03-14T09:56:43.843475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Scalling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "train = pd.read_csv('../input/cost-of-living/cost-of-living-2018.csv')\n",
    "plt.hist(train['Cost of Living Index'])\n",
    "plt.title(\"Histogram before Scalling\")\n",
    "plt.show()\n",
    "scaler = preprocessing.StandardScaler()\n",
    "train['Cost of Living Index'] = scaler.fit_transform(train['Cost of Living Index'].values.reshape(-1,1))\n",
    "plt.hist(train['Cost of Living Index'])\n",
    "plt.title(\"Histogram after Scalling\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:44.296880Z",
     "iopub.status.busy": "2021-03-14T09:56:44.295813Z",
     "iopub.status.idle": "2021-03-14T09:56:44.671788Z",
     "shell.execute_reply": "2021-03-14T09:56:44.671070Z"
    },
    "papermill": {
     "duration": 0.415878,
     "end_time": "2021-03-14T09:56:44.671908",
     "exception": false,
     "start_time": "2021-03-14T09:56:44.256030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Log Transformation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "train = pd.read_csv('../input/cost-of-living/cost-of-living-2018.csv')\n",
    "sns.distplot(train['Cost of Living Index'])\n",
    "plt.title(\"Distribution plot before Log transformation\")\n",
    "sns.despine()\n",
    "plt.show()\n",
    "train['Cost of Living Index'] = np.log(train['Cost of Living Index'])\n",
    "sns.distplot(train['Cost of Living Index'])\n",
    "plt.title(\"Distribution plot after Log transformation\")\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:44.745428Z",
     "iopub.status.busy": "2021-03-14T09:56:44.744579Z",
     "iopub.status.idle": "2021-03-14T09:56:45.113986Z",
     "shell.execute_reply": "2021-03-14T09:56:45.113330Z"
    },
    "papermill": {
     "duration": 0.410179,
     "end_time": "2021-03-14T09:56:45.114122",
     "exception": false,
     "start_time": "2021-03-14T09:56:44.703943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cube root Transformation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "train = pd.read_csv('../input/titanic/train.csv')\n",
    "plt.hist(train['Age'])\n",
    "plt.title(\"Histogram before cube root Transformation\")\n",
    "plt.show()\n",
    "train['Age'] = (train['Age']**(1/3))\n",
    "plt.hist(train['Age'])\n",
    "plt.title(\"Histogram after cube root Transformation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:45.193848Z",
     "iopub.status.busy": "2021-03-14T09:56:45.193160Z",
     "iopub.status.idle": "2021-03-14T09:56:45.431546Z",
     "shell.execute_reply": "2021-03-14T09:56:45.430961Z"
    },
    "papermill": {
     "duration": 0.283149,
     "end_time": "2021-03-14T09:56:45.431685",
     "exception": false,
     "start_time": "2021-03-14T09:56:45.148536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Box-transformation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy\n",
    "train = pd.read_csv('../input/cost-of-living/cost-of-living-2018.csv')\n",
    "sns.boxplot(train['Rent Index'])\n",
    "plt.title(\"Box Plot before outlier removing\")\n",
    "plt.show()\n",
    "train['Rent Index'],fitted_lambda= scipy.stats.boxcox(train['Rent Index'] ,lmbda=None)\n",
    "sns.boxplot(train['Rent Index'])\n",
    "plt.title(\"Box Plot after outlier removing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034399,
     "end_time": "2021-03-14T09:56:45.501320",
     "exception": false,
     "start_time": "2021-03-14T09:56:45.466921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div align='left'><font size=\"4\" color=\"#000000\"><h1 style=\"text-transform: uppercase\"><strong>Imputation</strong> </font></div>\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\">Like imputation of missing values, we can also impute outliers. We can use mean, median, zero value in this methods. Since we imputing there is no loss of data. Here median is appropriate because it is not affected by outliers.</font></div> \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:45.582787Z",
     "iopub.status.busy": "2021-03-14T09:56:45.581992Z",
     "iopub.status.idle": "2021-03-14T09:56:45.824768Z",
     "shell.execute_reply": "2021-03-14T09:56:45.824042Z"
    },
    "papermill": {
     "duration": 0.289176,
     "end_time": "2021-03-14T09:56:45.824893",
     "exception": false,
     "start_time": "2021-03-14T09:56:45.535717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#mean imputation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('../input/titanic/train.csv')\n",
    "sns.boxplot(train['Age'])\n",
    "plt.title(\"Box Plot before mean imputation\")\n",
    "plt.show()\n",
    "q1 = train['Age'].quantile(0.25)\n",
    "q3 = train['Age'].quantile(0.75)\n",
    "iqr = q3-q1\n",
    "Lower_tail = q1 - 1.5 * iqr\n",
    "Upper_tail = q3 + 1.5 * iqr\n",
    "m = np.mean(train['Age'])\n",
    "for i in train['Age']:\n",
    "    if i > Upper_tail or i < Lower_tail:\n",
    "            train['Age'] = train['Age'].replace(i, m)\n",
    "sns.boxplot(train['Age'])\n",
    "plt.title(\"Box Plot after mean imputation\")\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:45.910219Z",
     "iopub.status.busy": "2021-03-14T09:56:45.909474Z",
     "iopub.status.idle": "2021-03-14T09:56:46.407501Z",
     "shell.execute_reply": "2021-03-14T09:56:46.406891Z"
    },
    "papermill": {
     "duration": 0.546134,
     "end_time": "2021-03-14T09:56:46.407634",
     "exception": false,
     "start_time": "2021-03-14T09:56:45.861500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#median imputation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('../input/titanic/train.csv')\n",
    "sns.boxplot(train['Age'])\n",
    "plt.title(\"Box Plot before median imputation\")\n",
    "plt.show()\n",
    "q1 = train['Age'].quantile(0.25)\n",
    "q3 = train['Age'].quantile(0.75)\n",
    "iqr = q3-q1\n",
    "Lower_tail = q1 - 1.5 * iqr\n",
    "Upper_tail = q3 + 1.5 * iqr\n",
    "med = np.median(train['Age'])\n",
    "for i in train['Age']:\n",
    "    if i > Upper_tail or i < Lower_tail:\n",
    "            train['Age'] = train['Age'].replace(i, med)\n",
    "sns.boxplot(train['Age'])\n",
    "plt.title(\"Box Plot after median imputation\")\n",
    "plt.show()            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-14T09:56:46.496560Z",
     "iopub.status.busy": "2021-03-14T09:56:46.495437Z",
     "iopub.status.idle": "2021-03-14T09:56:46.739727Z",
     "shell.execute_reply": "2021-03-14T09:56:46.739167Z"
    },
    "papermill": {
     "duration": 0.292952,
     "end_time": "2021-03-14T09:56:46.739856",
     "exception": false,
     "start_time": "2021-03-14T09:56:46.446904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Zero value imputation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "train = pd.read_csv('../input/titanic/train.csv')\n",
    "sns.boxplot(train['Age'])\n",
    "plt.title(\"Box Plot before Zero value imputation\")\n",
    "plt.show()\n",
    "q1 = train['Age'].quantile(0.25)\n",
    "q3 = train['Age'].quantile(0.75)\n",
    "iqr = q3-q1\n",
    "Lower_tail = q1 - 1.5 * iqr\n",
    "Upper_tail = q3 + 1.5 * iqr\n",
    "for i in train['Age']:\n",
    "    if i > Upper_tail or i < Lower_tail:\n",
    "            train['Age'] = train['Age'].replace(i, 0)\n",
    "sns.boxplot(train['Age'])\n",
    "plt.title(\"Box Plot after Zero value imputation\")\n",
    "plt.show()            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seperately treating\n",
    "이상치의 수가 유의하고 데이터 집합이 작으면 통계 모형에서 특이치를 별도로 처리해야 합니다.\n",
    "접근법 중 하나는 두 그룹을 서로 다른 두 그룹으로 취급하고 두 그룹에 대한 개별 모델을 구축한 다음 출력을 결합하는 것입니다.\n",
    "그러나 데이터 세트가 클 경우 이 기술은 지루합니다\n",
    "\n",
    "# Conclusion\n",
    "1. median은 데이터에 outlier가 있거나 skewed된 경우 중심 경향을 측정하는 가장 좋은 척도\n",
    "2. Winsorization Method 또는 Percentile Caping은 이상값 검출 기법보다 우수합니다.\n",
    "3. 중위 귀속은 특이치를 완전히 제거한다.\n",
    "특이치는 기계 학습의 주요 문제 중 하나이다. 특이치 결과를 무시하면 모형의 성능이 저하됩니다. 이 커널에서 특이치, 특이치 탐지, 특이치 처리 기법과 관련된 거의 모든 항목을 다루려고 합니다.\n",
    "\n",
    "## Reference\n",
    "- https://medium.com/datadriveninvestor/finding-outliers-in-dataset-using-python-efc3fce6ce32\n",
    "- http://www.askanalytics.in/p/outlier-treatment.html\n",
    "- https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
    "- https://www.kdnuggets.com/2018/12/four-techniques-outlier-detection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.038543,
     "end_time": "2021-03-14T09:56:46.817092",
     "exception": false,
     "start_time": "2021-03-14T09:56:46.778549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div align='left'><font size=\"4\" color=\"#000000\"><h1 style=\"text-transform: uppercase\"><strong>Separately treating</strong> </font></div>\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\">If there are significant number of outliers and dataset is small , we should treat them separately in the statistical model. One of the approach is to treat both groups as two different groups and build individual model for both groups and then combine the output. But this technique is tedious when the dataset is large.</font></div> \n",
    "<hr>\n",
    "<div align='left'><font size=\"4\" color=\"#000000\"><h1 style=\"text-transform: uppercase\"><strong>Conclusion</strong> </font></div>\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\">1. Median is best measure of central tendency when the data has outlier or skewed.</font></div> \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">2. Winsorization Method or Percentile Capping is the better outlier detection technique the others.</font></div> \n",
    "<div align='left'><font size=\"3\" color=\"#000000\">3. Median imputation completely remove outlier.</font></div> \n",
    "<hr>\n",
    "<div align='left'><font size=\"3\" color=\"#000000\">Outlier is one of the major problem in machine learning. If you neglect the outlier result with bad performance of the model. In this kernel I'm try to cover almost all the topics related to outliers, outlier detection, outlier treatment techniques. </font></div> \n",
    "\n",
    "<hr>   \n",
    "<div class=\"alert alert-warning\" ><font size=\"3\"><strong>Please note that some of these techniques not gave the best result all the time. So be careful when you try to detect/impute outliers.</strong> </div><hr>  \n",
    "<div align='left'><font size=\"4\" color=\"#000000\"><h1 style=\"text-transform: uppercase\"><strong>References</strong> </font></div>\n",
    "<hr>\n",
    "<div align='left'><font size=\"3\"><a href=\"https://medium.com/datadriveninvestor/finding-outliers-in-dataset-using-python-efc3fce6ce32\" target=\"_blank\">1. Finding outliers in dataset using python</a></div>\n",
    "<div align='left'><font size=\"3\"><a href=\"http://www.askanalytics.in/p/outlier-treatment.html\" target=\"_blank\">2. Outlier Detection - Basics</a></div>\n",
    "<div align='left'><font size=\"3\"><a href=\"https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\" target=\"_blank\">3. Ways to Detect and Remove the Outliers</a></div>\n",
    "<div align='left'><font size=\"3\"><a href=\"https://www.kdnuggets.com/2018/12/four-techniques-outlier-detection.html\" target=\"_blank\">4. Four Techniques for Outlier Detection - KDnuggets</a></div>\n",
    "<hr>   \n",
    "<div class=\"alert alert-success\" ><font size=\"4\"><strong>Feel free to ask any question related to this topic. I'm happy to answer. If you like my work don't hesitate to upvote. HAPPY LEARNING :) </strong> </div>\n",
    "\n",
    "<img style=\"float: center;\"  src=\"https://img.pngio.com/thumbs-up-emoticon-thumb-up-and-down-emoji-png-image-thumbs-up-emoji-transparent-background-820_516.png\" width=\"450px\">\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "papermill": {
   "duration": 18.905296,
   "end_time": "2021-03-14T09:56:47.044063",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-14T09:56:28.138767",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
